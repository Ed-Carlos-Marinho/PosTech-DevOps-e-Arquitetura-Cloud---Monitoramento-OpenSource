# =============================================================================
# PROMTAIL CONFIGURATION - DISTRIBUTED APPLICATIONS INSTANCE
# =============================================================================
# Configuração do Promtail para coleta de logs das aplicações distribuídas
# Aula 05 - PosTech DevOps e Arquitetura Cloud - Monitoramento OpenSource
# Foco: Coleta de logs com correlação de traces (trace_id)
# =============================================================================

# -----------------------------------------------------------------------------
# CONFIGURAÇÕES DO SERVIDOR
# -----------------------------------------------------------------------------
server:
  http_listen_port: 9080                    # Porta HTTP para métricas e healthcheck
  grpc_listen_port: 0                       # Porta gRPC (0 = desabilitado)
  log_level: info                           # Nível de log (debug, info, warn, error)

# -----------------------------------------------------------------------------
# CONFIGURAÇÕES DE POSIÇÕES (Controle de leitura de arquivos)
# -----------------------------------------------------------------------------
positions:
  filename: /tmp/positions/positions.yaml   # Arquivo para salvar posições de leitura
  sync_period: 10s                          # Intervalo de sincronização das posições
  ignore_invalid_yaml: false                # Ignora YAML inválido no arquivo de posições

# -----------------------------------------------------------------------------
# CONFIGURAÇÕES DO CLIENTE LOKI
# -----------------------------------------------------------------------------
clients:
  - url: http://LOKI_SERVER_IP:3100/loki/api/v1/push  # URL da API do Loki para envio de logs
    tenant_id: ""                           # ID do tenant (vazio para single-tenant)
    
    # Configurações de batching (agrupamento de logs)
    batchwait: 1s                           # Tempo de espera antes de enviar batch
    batchsize: 1048576                      # Tamanho máximo do batch (1MB)
    
    # Configurações de retry (tentativas de reenvio)
    backoff_config:
      min_period: 500ms                     # Período mínimo entre tentativas
      max_period: 5m                        # Período máximo entre tentativas
      max_retries: 10                       # Número máximo de tentativas
    
    # Configurações de timeout
    timeout: 10s                            # Timeout para requisições HTTP

# -----------------------------------------------------------------------------
# CONFIGURAÇÕES DE COLETA DE LOGS (SCRAPE CONFIGS)
# -----------------------------------------------------------------------------
scrape_configs:
  
  # ---------------------------------------------------------------------------
  # JOB 1: LOGS DO FRONTEND SERVICE
  # ---------------------------------------------------------------------------
  - job_name: frontend-service
    
    static_configs:
      - targets:
          - localhost
        labels:
          job: frontend-service
          host: distributed-app-server
          service: frontend
          __path__: /app/logs/frontend/frontend.log
    
    # Pipeline de processamento dos logs do frontend
    pipeline_stages:
      
      # Estágio 1: Parsing do JSON estruturado
      - json:
          expressions:
            timestamp: timestamp
            level: level
            message: message
            trace_id: trace_id
            span_id: span_id
            endpoint: endpoint
            method: method
            status: status
      
      # Estágio 2: Adicionar labels baseados no conteúdo
      - labels:
          level: level
          trace_id: trace_id
          span_id: span_id
      
      # Estágio 3: Parsing de timestamp
      - timestamp:
          source: timestamp
          format: RFC3339
      
      # Estágio 4: Classificar por tipo de operação
      - match:
          selector: '{job="frontend-service"}'
          stages:
            - regex:
                expression: '"endpoint":"(?P<endpoint_path>[^"]+)"'
                source: message
            - labels:
                endpoint: endpoint_path

  # ---------------------------------------------------------------------------
  # JOB 2: LOGS DO BACKEND SERVICE
  # ---------------------------------------------------------------------------
  - job_name: backend-service
    
    static_configs:
      - targets:
          - localhost
        labels:
          job: backend-service
          host: distributed-app-server
          service: backend
          __path__: /app/logs/backend/backend.log
    
    # Pipeline de processamento dos logs do backend
    pipeline_stages:
      
      # Estágio 1: Parsing do JSON estruturado
      - json:
          expressions:
            timestamp: timestamp
            level: level
            message: message
            trace_id: trace_id
            span_id: span_id
            event: event
            user_id: user_id
            order_id: order_id
      
      # Estágio 2: Adicionar labels baseados no conteúdo
      - labels:
          level: level
          trace_id: trace_id
          span_id: span_id
          event: event
      
      # Estágio 3: Parsing de timestamp
      - timestamp:
          source: timestamp
          format: RFC3339
      
      # Estágio 4: Classificar por tipo de operação de banco
      - match:
          selector: '{job="backend-service"}'
          stages:
            - regex:
                expression: '"event":"(?P<db_operation>database_[^"]+)"'
                source: message
            - labels:
                db_operation: db_operation

  # ---------------------------------------------------------------------------
  # JOB 3: LOGS DO POSTGRESQL
  # ---------------------------------------------------------------------------
  - job_name: postgres-logs
    
    static_configs:
      - targets:
          - localhost
        labels:
          job: postgres-logs
          host: distributed-app-server
          service: postgres
          __path__: /var/lib/docker/containers/*/postgres-db-*.log
    
    # Pipeline para logs do PostgreSQL via Docker
    pipeline_stages:
      
      # Parsing do formato JSON dos logs do Docker
      - json:
          expressions:
            output: log
            stream: stream
            time: time
      
      # Adicionar stream como label
      - labels:
          stream: stream
      
      # Parsing de timestamp do Docker
      - timestamp:
          source: time
          format: RFC3339Nano
      
      # Usar o campo 'output' como conteúdo da linha
      - output:
          source: output
      
      # Extrair informações específicas do PostgreSQL
      - regex:
          expression: '(?P<log_level>LOG|ERROR|WARNING|FATAL):\s+(?P<pg_message>.*)'
          source: output
      
      # Adicionar nível do PostgreSQL como label
      - labels:
          pg_level: log_level

  # ---------------------------------------------------------------------------
  # JOB 4: LOGS DO REDIS
  # ---------------------------------------------------------------------------
  - job_name: redis-logs
    
    static_configs:
      - targets:
          - localhost
        labels:
          job: redis-logs
          host: distributed-app-server
          service: redis
          __path__: /var/lib/docker/containers/*/redis-cache-*.log
    
    # Pipeline para logs do Redis via Docker
    pipeline_stages:
      
      # Parsing do formato JSON dos logs do Docker
      - json:
          expressions:
            output: log
            stream: stream
            time: time
      
      # Adicionar stream como label
      - labels:
          stream: stream
      
      # Parsing de timestamp do Docker
      - timestamp:
          source: time
          format: RFC3339Nano
      
      # Usar o campo 'output' como conteúdo da linha
      - output:
          source: output

  # ---------------------------------------------------------------------------
  # JOB 5: LOGS DO RABBITMQ
  # ---------------------------------------------------------------------------
  - job_name: rabbitmq-logs
    
    static_configs:
      - targets:
          - localhost
        labels:
          job: rabbitmq-logs
          host: distributed-app-server
          service: rabbitmq
          __path__: /var/lib/docker/containers/*/rabbitmq-queue-*.log
    
    # Pipeline para logs do RabbitMQ via Docker
    pipeline_stages:
      
      # Parsing do formato JSON dos logs do Docker
      - json:
          expressions:
            output: log
            stream: stream
            time: time
      
      # Adicionar stream como label
      - labels:
          stream: stream
      
      # Parsing de timestamp do Docker
      - timestamp:
          source: time
          format: RFC3339Nano
      
      # Usar o campo 'output' como conteúdo da linha
      - output:
          source: output
      
      # Extrair informações específicas do RabbitMQ
      - regex:
          expression: '(?P<rabbit_timestamp>\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}\.\d{3}) \[(?P<rabbit_level>\w+)\] (?P<rabbit_message>.*)'
          source: output
      
      # Adicionar nível do RabbitMQ como label
      - labels:
          rabbit_level: rabbit_level

  # ---------------------------------------------------------------------------
  # JOB 6: LOGS DO SISTEMA (SYSLOG)
  # ---------------------------------------------------------------------------
  - job_name: syslog
    
    static_configs:
      - targets:
          - localhost
        labels:
          job: syslog
          host: distributed-app-server
          service: system
          __path__: /var/log/syslog
    
    # Pipeline básico para syslog
    pipeline_stages:
      
      # Parsing básico do syslog
      - regex:
          expression: '^(?P<timestamp>\w+\s+\d+\s+\d+:\d+:\d+)\s+(?P<hostname>\S+)\s+(?P<service>\S+):\s*(?P<message>.*)'
          source: ""
      
      # Adicionar labels
      - labels:
          hostname: hostname
          syslog_service: service
      
      # Parsing de timestamp do syslog
      - timestamp:
          source: timestamp
          format: 'Jan 02 15:04:05'
          fallback_formats:
            - "2006-01-02T15:04:05.000Z"
            - "2006-01-02 15:04:05"

# =============================================================================
# INTEGRAÇÃO COM LOKI - INSTÂNCIA 2:
# =============================================================================
# 1. Este Promtail coleta logs de aplicações distribuídas instrumentadas
# 2. Logs são enviados para Loki na Instância 1
# 3. Labels organizados por job, service, level, trace_id
# 4. Pipelines específicos para cada tipo de log e serviço
# 5. Correlação automática com traces via trace_id
#
# CONSULTAS LOGQL RESULTANTES:
# - {job="frontend-service"}: Logs do frontend
# - {job="backend-service"}: Logs do backend
# - {job="postgres-logs"}: Logs do PostgreSQL
# - {job="redis-logs"}: Logs do Redis
# - {job="rabbitmq-logs"}: Logs do RabbitMQ
# - {trace_id="abc123"}: Todos os logs de um trace específico
# - {level="error"}: Todos os logs de erro
# - {service="backend"} |= "database": Logs de operações de banco
# =============================================================================
#
# CORRELAÇÃO COM TRACES:
# =============================================================================
# Use estas consultas em dashboards Grafana para correlacionar:
#
# 1. Logs por trace_id:
#    - LogQL: {job=~"frontend-service|backend-service"} | json | trace_id="TRACE_ID"
#
# 2. Logs de erro correlacionados:
#    - LogQL: {level="error"} | json | trace_id!=""
#
# 3. Performance de operações:
#    - LogQL: {job="backend-service"} |= "processing.time_ms"
#    - Correlacionar com spans do Jaeger
# =============================================================================
#
# CONFIGURAÇÃO NECESSÁRIA:
# =============================================================================
# 1. Substituir LOKI_SERVER_IP pelo IP privado da Instância 1
# 2. Exemplo: sed -i 's/LOKI_SERVER_IP/10.0.1.100/' promtail-app-config.yml
# 3. Reiniciar Promtail: docker-compose restart promtail
# =============================================================================